---
---

@inproceedings{rahamim2024fast,
  title={Fast Forwarding Low-Rank Training},
  author={Rahamim, Adir and Saphra, Naomi and Kangaslahti, Sara and Belinkov, Yonatan},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={9553--9562},
  year={2024}
}

@article{ebanks2025topic,
  title={Topic Models Estimators Are Statistically Inconsistent and Substantively Misleading: Evidence and Solutions},
  author={Ebanks, Danny and Kangaslahti, Sara},
  year={2025}
}

@inproceedings{kocielnik2023can,
  title={Can you label less by using out-of-domain data? Active \& transfer learning with few-shot instructions},
  author={Kocielnik, Rafal and Kangaslahti, Sara and Prabhumoye, Shrimai and Hari, Meena and Alvarez, Michael and Anandkumar, Anima},
  booktitle={Transfer Learning for Natural Language Processing Workshop},
  pages={22--32},
  year={2023},
  organization={PMLR}
}

@article{kemna2021adaptive,
  title={Adaptive sampling: Algorithmic vs. human waypoint selection},
  author={Kemna, Stephanie and Kangaslahti, Sara and Kroemer, Oliver and Sukhatme, Gaurav S},
  journal={arXiv preprint arXiv:2104.11962},
  year={2021}
}

@article{kangaslahti2025continuous,
  title={Continuous Language Model Interpolation for Dynamic and Controllable Text Generation},
  author={Kangaslahti, Sara and Alvarez-Melis, David},
  journal={Transactions on Machine Learning Research},
  year={2025}
}

@article{kangaslahti2025analyzing,
  title={Analyzing Political Text at Scale with Online Tensor LDA},
  author={Kangaslahti, Sara and Ebanks, Danny and Kossaifi, Jean and Liu, Anqi and Alvarez, R Michael and Anandkumar, Animashree},
  year={2025}
}

@article{much2024activating,
  title={Activating Identity and Political Action in the\# Metoo Era},
  author={Much, Melina and Ebanks, Daniel and Kangaslahti, Sara and Kossaifi, Jean and Alvarez, R Michael and Liu, Anqi and Anandkumar, Anima},
  journal={Available at SSRN 5289639},
  year={2024}
}

@article{kangaslahti2025hidden,
  title={Hidden Breakthroughs in Language Model Training},
  author={Kangaslahti, Sara and Rosenfeld, Elan and Saphra, Naomi},
  journal={arXiv preprint arXiv:2506.15872},
  year={2025}
}

@article{kangaslahti2025boomerang,
  title={Boomerang Distillation Enables Zero-Shot Model Size Interpolation},
  author={Kangaslahti, Sara and Nayak, Nihal V and Geuter, Jonathan and Fumero, Marco and Locatello, Francesco and Alvarez-Melis, David},
  journal={arXiv preprint arXiv:2510.05064},
  year={2025}
}